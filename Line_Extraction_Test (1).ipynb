{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "EhSIEOmKGYV4",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "#CELL 1\n",
    "!pip install -q openai opencv-python-headless scikit-image matplotlib pandas imutils scikit-learn xlsxwriter Pillow scipy shapely"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIxLHxWNGdtA"
   },
   "outputs": [],
   "source": [
    "#CELL 2\n",
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from ipywidgets import widgets\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "from skimage.morphology import skeletonize\n",
    "import openai\n",
    "import xlsxwriter\n",
    "import imutils\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import UnivariateSpline, interp1d\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjPzRdRyGnkX"
   },
   "outputs": [],
   "source": [
    "#CELL 3\n",
    "try:\n",
    "    api_key = input(\"Enter your API key (or press Enter to skip): \").strip()\n",
    "\n",
    "    if api_key and api_key.startswith('sk-'):\n",
    "        openai.api_key = api_key\n",
    "        print(\"API key configured successfully!\")\n",
    "        print(\"Universal graph analysis will be available.\")\n",
    "        gpt_available = True\n",
    "    else:\n",
    "        print(\"Skipping API key. GPT features will be disabled.\")\n",
    "        print(\"Basic extraction features remain fully functional.\")\n",
    "        gpt_available = False\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"API key setup failed. Please continue without GPT features.\")\n",
    "    gpt_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQYnjCyOGsCe"
   },
   "outputs": [],
   "source": [
    "#CELL 4\n",
    "print(\"UPLOAD YOUR SCIENTIFIC GRAPH\")\n",
    "print(\"Supported formats: PNG, JPG, JPEG\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    image_path = list(uploaded.keys())[0]\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(\"Original Graph for Processing\", fontsize=16, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        height, width = image_np.shape[:2]\n",
    "\n",
    "        print(f\"Image uploaded successfully: {image_path}\")\n",
    "        print(f\"Image dimensions: {width} x {height} pixels\")\n",
    "        print(f\"file size: {len(uploaded[image_path])} bytes\")\n",
    "\n",
    "        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "        contrast = np.std(gray)\n",
    "\n",
    "        if contrast > 50:\n",
    "            print(\"Image is ready for extraction.\")\n",
    "        elif contrast > 25:\n",
    "            print(\"Moderate image contrast. Extraction should work.\")\n",
    "        else:\n",
    "            print(\"Low image contrast. May need parameter adjustment.\")\n",
    "\n",
    "        if gpt_available:\n",
    "            img_buffer = io.BytesIO()\n",
    "            Image.fromarray(image_np).save(img_buffer, format='PNG')\n",
    "            img_base64 = base64.b64encode(img_buffer.getvalue()).decode()\n",
    "        else:\n",
    "            img_base64 = None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {str(e)}\")\n",
    "        print(\"Please try uploading a different image file\")\n",
    "\n",
    "else:\n",
    "    print(\"No image uploaded. Please run this cell again and select an image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEpnjFWWGymD"
   },
   "outputs": [],
   "source": [
    "#CELL 5\n",
    "print(\"INTELLIGENT GRAPH ANALYSIS ROUTER\")\n",
    "\n",
    "class GraphAnalysisRouter:\n",
    "    def __init__(self, image_np, gpt_available=False):\n",
    "        self.image = image_np\n",
    "        self.gpt_available = gpt_available\n",
    "        self.image_bounds = None\n",
    "        self.detected_colors = None\n",
    "\n",
    "    def route_and_execute(self, user_request):\n",
    "        print(f\"Processing: '{user_request}'\")\n",
    "\n",
    "        intent = self._parse_intent(user_request)\n",
    "        print(f\"Intent: {intent['type']}\")\n",
    "\n",
    "        if intent['type'] == 'curve_extraction':\n",
    "            return self._trigger_extraction_pipeline(intent)\n",
    "        elif intent['type'] == 'axis_analysis':\n",
    "            return self._analyze_axes(intent)\n",
    "        elif intent['type'] == 'color_detection':\n",
    "            return self._trigger_color_detection()\n",
    "        elif intent['type'] == 'coordinates':\n",
    "            return self._handle_coordinates(intent)\n",
    "        elif intent['type'] == 'excel_export':\n",
    "            return self._trigger_excel_export(intent)\n",
    "        elif intent['type'] == 'general_visual':\n",
    "            return self._general_analysis(intent)\n",
    "        else:\n",
    "            return self._handle_other(intent)\n",
    "\n",
    "    def _parse_intent(self, request):\n",
    "        request_lower = request.lower()\n",
    "\n",
    "        if any(word in request_lower for word in ['extract', 'curve', 'line', 'data']):\n",
    "            colors = self._extract_color_mentions(request)\n",
    "            return {\n",
    "                'type': 'curve_extraction',\n",
    "                'colors': colors,\n",
    "                'mode': 'selective' if colors else 'auto'\n",
    "            }\n",
    "        elif any(word in request_lower for word in ['axis', 'axes', 'scale', 'range']):\n",
    "            return {'type': 'axis_analysis'}\n",
    "        elif any(word in request_lower for word in ['color', 'available']):\n",
    "            return {'type': 'color_detection'}\n",
    "        elif 'coordinate' in request_lower:\n",
    "            return {'type': 'coordinates', 'coord_type': None}\n",
    "        elif any(word in request_lower for word in ['excel', 'export', 'create excel', 'download', 'save']):\n",
    "            return {'type': 'excel_export', 'action': 'create' if 'create' in request_lower else 'approve'}\n",
    "        else:\n",
    "            return {'type': 'general_visual'}\n",
    "\n",
    "    def _extract_color_mentions(self, request):\n",
    "        colors = []\n",
    "        color_words = ['black', 'red', 'blue', 'green', 'yellow', 'teal', 'purple', 'orange', 'brown', 'gray', 'cyan', 'magenta']\n",
    "\n",
    "        for color in color_words:\n",
    "            if color in request.lower():\n",
    "                colors.append(color)\n",
    "        return colors\n",
    "\n",
    "    def _trigger_extraction_pipeline(self, intent):\n",
    "        print(\"Triggering extraction pipeline...\")\n",
    "\n",
    "        target_colors = intent.get('colors', [])\n",
    "        if target_colors:\n",
    "            print(f\"Will extract: {target_colors}\")\n",
    "            global user_requested_colors, user_extraction_mode\n",
    "            user_requested_colors = target_colors\n",
    "            user_extraction_mode = \"selective\"\n",
    "        else:\n",
    "            print(f\"Will auto-detect all available colors\")\n",
    "            user_extraction_mode = \"auto\"\n",
    "            user_requested_colors = []\n",
    "\n",
    "        try:\n",
    "            global pipeline_triggered_by_router\n",
    "            pipeline_triggered_by_router = True\n",
    "\n",
    "            print(\"Executing Cell 6 (Color Detection)...\")\n",
    "            self._execute_cell_6()\n",
    "\n",
    "            print(\"Executing Cell 7 (Infrastructure Removal)...\")\n",
    "            self._execute_cell_7()\n",
    "\n",
    "            print(\"Executing Cell 8 (Curve Extraction)...\")\n",
    "            self._execute_cell_8()\n",
    "\n",
    "            print(\"Executing Cell 10 (Quality Assessment)...\")\n",
    "            self._execute_cell_10()\n",
    "\n",
    "            print(\"Pipeline execution complete!\")\n",
    "\n",
    "            if 'extracted_curves' in globals() and extracted_curves:\n",
    "                total_points = sum(curve['point_count'] for curve in extracted_curves.values())\n",
    "\n",
    "                print(\"PIPELINE COMPLETE - READY FOR VISUALIZATION\")\n",
    "                print(f\"Curves extracted: {len(extracted_curves)}\")\n",
    "                print(f\"Total points: {total_points}\")\n",
    "                print(f\"Curves ready: {list(extracted_curves.keys())}\")\n",
    "                print(f\"\\nNOW RUN CELL 11 TO SEE THE VISUALIZATION!\")\n",
    "                print(\"Click the play button on Cell 11 to display the extracted curves\")\n",
    "\n",
    "                return {\n",
    "                    'type': 'curve_extraction',\n",
    "                    'results': extracted_curves,\n",
    "                    'summary': f\"Pipeline complete: extracted {len(extracted_curves)} curves with {total_points} total points\",\n",
    "                    'pipeline_executed': True,\n",
    "                    'cells_executed': ['6', '7', '8', '10'],\n",
    "                    'next_step': 'RUN CELL 11 to see visualization, then ask \"create excel file\" to export'\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'type': 'curve_extraction',\n",
    "                    'results': {},\n",
    "                    'summary': 'Pipeline executed but no curves were extracted',\n",
    "                    'pipeline_executed': True,\n",
    "                    'suggestion': 'Try different colors or check image quality'\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Pipeline execution failed: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                'type': 'curve_extraction',\n",
    "                'results': {},\n",
    "                'summary': f'Pipeline execution failed: {str(e)}',\n",
    "                'pipeline_executed': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def _execute_cell_6(self):\n",
    "        print(\"Running color detection from Cell 6...\")\n",
    "\n",
    "        try:\n",
    "            exec(\"\"\"\n",
    "print(\"SCANNING IMAGE FOR AVAILABLE COLORS...\")\n",
    "print(\"Analyzing pixel distributions and color presence...\")\n",
    "\n",
    "hsv_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "detected_colors = {}\n",
    "min_pixel_threshold = 50\n",
    "\n",
    "def analyze_color_presence(hsv_img, color_name, color_range):\n",
    "    lower_hsv, upper_hsv = color_range\n",
    "    lower = np.array(lower_hsv)\n",
    "    upper = np.array(upper_hsv)\n",
    "\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "    pixel_count = np.count_nonzero(mask)\n",
    "\n",
    "    if pixel_count > 0:\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "        if num_labels > 1:\n",
    "            largest_component = np.max(stats[1:, cv2.CC_STAT_AREA])\n",
    "            distribution_quality = largest_component / pixel_count\n",
    "        else:\n",
    "            distribution_quality = 0\n",
    "    else:\n",
    "        distribution_quality = 0\n",
    "\n",
    "    return {\n",
    "        'pixel_count': pixel_count,\n",
    "        'distribution_quality': distribution_quality,\n",
    "        'mask': mask,\n",
    "        'present': pixel_count > min_pixel_threshold\n",
    "    }\n",
    "\n",
    "print(\"\\\\nColor Detection Results:\")\n",
    "\n",
    "selected_colors = {\n",
    "    'black': ((0, 0, 0), (180, 30, 30)),\n",
    "    'red': ((0, 70, 50), (10, 255, 255)),\n",
    "    'blue': ((90, 50, 50), (130, 255, 255)),\n",
    "    'green': ((36, 50, 70), (89, 255, 255)),\n",
    "    'yellow': ((15, 100, 100), (35, 255, 255)),\n",
    "    'teal': ((85, 50, 50), (100, 255, 255)),\n",
    "    'purple': ((120, 50, 50), (150, 255, 255)),\n",
    "    'orange': ((10, 50, 50), (25, 255, 255)),\n",
    "    'brown': ((10, 50, 20), (20, 255, 200)),\n",
    "    'gray': ((0, 0, 50), (180, 50, 200)),\n",
    "    'cyan': ((80, 50, 50), (90, 255, 255)),\n",
    "    'magenta': ((150, 50, 50), (170, 255, 255))\n",
    "}\n",
    "\n",
    "for color_name, color_range in selected_colors.items():\n",
    "    analysis = analyze_color_presence(hsv_image, color_name, color_range)\n",
    "\n",
    "    if analysis['present']:\n",
    "        detected_colors[color_name] = {\n",
    "            'range': color_range,\n",
    "            'pixel_count': analysis['pixel_count'],\n",
    "            'quality': analysis['distribution_quality'],\n",
    "            'mask': analysis['mask']\n",
    "        }\n",
    "\n",
    "        quality_desc = \"High\" if analysis['distribution_quality'] > 0.3 else \"Medium\" if analysis['distribution_quality'] > 0.1 else \"Low\"\n",
    "        print(f\"{color_name:8}: {analysis['pixel_count']:5} pixels (Quality: {quality_desc})\")\n",
    "    else:\n",
    "        print(f\"{color_name:8}: {analysis['pixel_count']:5} pixels (Below threshold)\")\n",
    "\n",
    "if detected_colors:\n",
    "    print(f\"\\\\nFound {len(detected_colors)} processable colors\")\n",
    "else:\n",
    "    print(\"\\\\nNo colors detected above threshold!\")\n",
    "\n",
    "print(f\"\\\\nSummary: {len(detected_colors)} colors ready for processing\")\n",
    "            \"\"\", globals())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Cell 6 execution failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def _execute_cell_7(self):\n",
    "        print(\"Running infrastructure removal from Cell 7...\")\n",
    "\n",
    "        try:\n",
    "            exec(\"\"\"\n",
    "print(\"DETECTING AND REMOVING GRAPH INFRASTRUCTURE...\")\n",
    "\n",
    "def detect_text_regions(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    text_mask = np.zeros_like(gray)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if 10 < area < 500 and 0.2 < h/w < 5:\n",
    "            cv2.fillPoly(text_mask, [contour], 255)\n",
    "    return text_mask\n",
    "\n",
    "def detect_straight_lines(image, min_line_length=50):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,\n",
    "                           minLineLength=min_line_length, maxLineGap=10)\n",
    "    line_mask = np.zeros_like(gray)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "            angle = np.arctan2(y2-y1, x2-x1) * 180 / np.pi\n",
    "            is_horizontal = abs(angle) < 5 or abs(angle-180) < 5\n",
    "            is_vertical = abs(angle-90) < 5 or abs(angle+90) < 5\n",
    "            if length > min_line_length * 2 or is_horizontal or is_vertical:\n",
    "                cv2.line(line_mask, (x1, y1), (x2, y2), 255, 3)\n",
    "    return line_mask\n",
    "\n",
    "print(\"Detecting text regions...\")\n",
    "text_mask = detect_text_regions(image_np)\n",
    "\n",
    "print(\"Detecting straight lines (axes, grids)...\")\n",
    "line_mask = detect_straight_lines(image_np)\n",
    "\n",
    "infrastructure_mask = cv2.bitwise_or(text_mask, line_mask)\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "infrastructure_mask = cv2.morphologyEx(infrastructure_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cleaned_image = image_np.copy()\n",
    "infrastructure_coords = np.where(infrastructure_mask == 255)\n",
    "cleaned_image[infrastructure_coords] = [255, 255, 255]\n",
    "\n",
    "print(\"Infrastructure removal complete\")\n",
    "            \"\"\", globals())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Cell 7 execution failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def _execute_cell_8(self):\n",
    "        \"\"\"Execute Cell 8 - Curve Extraction\"\"\"\n",
    "        print(\"Running curve extraction from Cell 8...\")\n",
    "\n",
    "        try:\n",
    "            exec(\"\"\"\n",
    "print(\"INTELLIGENT CURVE EXTRACTION - RESPECTING USER PREFERENCES\")\n",
    "\n",
    "# Filter colors based on user request\n",
    "if 'user_extraction_mode' in globals():\n",
    "    extraction_mode = user_extraction_mode\n",
    "    requested_colors = user_requested_colors if 'user_requested_colors' in globals() else []\n",
    "else:\n",
    "    extraction_mode = \"auto\"\n",
    "    requested_colors = []\n",
    "\n",
    "print(f\"\\\\nFILTERING COLORS BASED ON USER REQUEST...\")\n",
    "print(f\"Original detected colors: {list(detected_colors.keys())}\")\n",
    "\n",
    "def filter_colors_by_user_request(detected_colors, mode, requested_colors):\n",
    "    if mode == \"auto\":\n",
    "        filtered_colors = detected_colors.copy()\n",
    "        print(f\"AUTO MODE: Using all {len(filtered_colors)} detected colors\")\n",
    "        return filtered_colors\n",
    "    elif mode == \"selective\":\n",
    "        filtered_colors = {}\n",
    "        for color in requested_colors:\n",
    "            if color in detected_colors:\n",
    "                filtered_colors[color] = detected_colors[color]\n",
    "                print(f\"{color.upper()}: Found and will be extracted ({detected_colors[color]['pixel_count']} pixels)\")\n",
    "        return filtered_colors\n",
    "    else:\n",
    "        return detected_colors.copy()\n",
    "\n",
    "processing_colors = filter_colors_by_user_request(detected_colors, extraction_mode, requested_colors)\n",
    "\n",
    "# Set up axis calibration\n",
    "height, width = image_np.shape[:2]\n",
    "axis_calibration = {\n",
    "    'x_pixel': [int(width * 0.15), int(width * 0.90)],\n",
    "    'y_pixel': [int(height * 0.85), int(height * 0.10)],\n",
    "    'x_real': [0, 1000],\n",
    "    'y_real': [0.001, 10],\n",
    "    'x_scale': 'linear',\n",
    "    'y_scale': 'log10',\n",
    "    'bounds': (int(width * 0.15), int(height * 0.10), int(width * 0.90), int(height * 0.85))\n",
    "}\n",
    "\n",
    "# Extract curves using the original algorithms from Cell 8\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "def trace_black_curve_enhanced(image_np, graph_bounds):\n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "    left, top, right, bottom = graph_bounds\n",
    "    margin = 15\n",
    "    roi = (top + margin, bottom - margin, left + margin, right - margin)\n",
    "    y1, y2, x1, x2 = roi\n",
    "    roi_img = gray[y1:y2, x1:x2]\n",
    "    roi_rgb = image_np[y1:y2, x1:x2]\n",
    "\n",
    "    hsv = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2HSV)\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([180, 50, 80])\n",
    "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "    _, gray_thresh = cv2.threshold(roi_img, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "    edges = cv2.bitwise_or(black_mask, gray_thresh)\n",
    "\n",
    "    kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "    kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 20))\n",
    "    horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_h)\n",
    "    vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_v)\n",
    "    edges = cv2.subtract(edges, horizontal_lines)\n",
    "    edges = cv2.subtract(edges, vertical_lines)\n",
    "\n",
    "    skeleton = skeletonize(edges > 0)\n",
    "    num_lbl, lbl, stats, _ = cv2.connectedComponentsWithStats(skeleton.astype(np.uint8), connectivity=8)\n",
    "\n",
    "    if num_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    best_component = None\n",
    "    best_score = 0\n",
    "\n",
    "    for i in range(1, num_lbl):\n",
    "        if stats[i, cv2.CC_STAT_AREA] < 50:\n",
    "            continue\n",
    "        mask = (lbl == i)\n",
    "        ys, xs = np.where(mask)\n",
    "        pts = np.column_stack([xs, ys])\n",
    "        if len(pts) < 20:\n",
    "            continue\n",
    "        x_span = np.max(pts[:, 0]) - np.min(pts[:, 0])\n",
    "        y_span = np.max(pts[:, 1]) - np.min(pts[:, 1])\n",
    "        if x_span < 100 or y_span < 30:\n",
    "            continue\n",
    "        aspect_ratio = x_span / max(y_span, 1)\n",
    "        area_score = stats[i, cv2.CC_STAT_AREA]\n",
    "        score = area_score * aspect_ratio\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_component = i\n",
    "\n",
    "    if best_component is None:\n",
    "        return None\n",
    "\n",
    "    mask = (lbl == best_component)\n",
    "    ys, xs = np.where(mask)\n",
    "    pts = np.column_stack([xs, ys])\n",
    "    pts = pts[np.argsort(pts[:, 0])]\n",
    "    unique_x = np.unique(pts[:, 0])\n",
    "\n",
    "    if len(unique_x) < len(pts):\n",
    "        new_pts = []\n",
    "        for ux in unique_x:\n",
    "            y_vals = pts[pts[:, 0] == ux, 1]\n",
    "            median_y = np.median(y_vals)\n",
    "            new_pts.append([ux, median_y])\n",
    "        pts = np.array(new_pts)\n",
    "\n",
    "    pts[:, 0] += x1\n",
    "    pts[:, 1] += y1\n",
    "    return pts\n",
    "\n",
    "def extract_simple_curve(image_np, graph_bounds, color_name, color_range):\n",
    "    left, top, right, bottom = graph_bounds\n",
    "    legend_margin = 80\n",
    "    border_margin = 20\n",
    "    data_left = left + border_margin\n",
    "    data_top = top + border_margin\n",
    "    data_right = right - legend_margin\n",
    "    data_bottom = bottom - border_margin\n",
    "    data_roi = image_np[data_top:data_bottom, data_left:data_right]\n",
    "\n",
    "    hsv_roi = cv2.cvtColor(data_roi, cv2.COLOR_RGB2HSV)\n",
    "    lower_hsv, upper_hsv = color_range\n",
    "    lower = np.array(lower_hsv)\n",
    "    upper = np.array(upper_hsv)\n",
    "    mask = cv2.inRange(hsv_roi, lower, upper)\n",
    "\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    skeleton = skeletonize(mask > 0)\n",
    "    coords = np.column_stack(np.where(skeleton.T))\n",
    "\n",
    "    if len(coords) == 0:\n",
    "        return None\n",
    "\n",
    "    coords = coords[coords[:, 0].argsort()]\n",
    "    unique_coords = []\n",
    "    current_x = None\n",
    "    y_values = []\n",
    "\n",
    "    for x, y in coords:\n",
    "        if current_x is None or x != current_x:\n",
    "            if current_x is not None:\n",
    "                avg_y = np.median(y_values)\n",
    "                unique_coords.append([current_x, avg_y])\n",
    "            current_x = x\n",
    "            y_values = [y]\n",
    "        else:\n",
    "            y_values.append(y)\n",
    "\n",
    "    if current_x is not None:\n",
    "        avg_y = np.median(y_values)\n",
    "        unique_coords.append([current_x, avg_y])\n",
    "\n",
    "    if len(unique_coords) == 0:\n",
    "        return None\n",
    "\n",
    "    final_coords = np.array(unique_coords)\n",
    "    final_coords[:, 0] += data_left\n",
    "    final_coords[:, 1] += data_top\n",
    "    return final_coords\n",
    "\n",
    "# Extract curves\n",
    "extracted_curves = {}\n",
    "\n",
    "for color_name, color_data in processing_colors.items():\n",
    "    print(f\"\\\\nPROCESSING '{color_name.upper()}'...\")\n",
    "\n",
    "    if color_name == 'black':\n",
    "        print(\"\\\\tUSING ADVANCED BLACK CURVE ALGORITHM...\")\n",
    "        curve_points = trace_black_curve_enhanced(image_np, axis_calibration['bounds'])\n",
    "    else:\n",
    "        print(f\"\\\\tUSING SIMPLE DIRECT ALGORITHM...\")\n",
    "        curve_points = extract_simple_curve(image_np, axis_calibration['bounds'], color_name, color_data['range'])\n",
    "\n",
    "    if curve_points is not None:\n",
    "        extracted_curves[color_name] = {\n",
    "            'pixel_coordinates': curve_points,\n",
    "            'point_count': len(curve_points),\n",
    "            'scientific_coordinates': ([], []),\n",
    "            'confidence': color_data['quality'],\n",
    "            'x_range': (np.min(curve_points[:, 0]), np.max(curve_points[:, 0])),\n",
    "            'y_range': (np.min(curve_points[:, 1]), np.max(curve_points[:, 1]))\n",
    "        }\n",
    "        print(f\"\\\\t{color_name.upper()}: {len(curve_points)} points extracted successfully\")\n",
    "    else:\n",
    "        print(f\"\\\\t{color_name.upper()}: No curve found\")\n",
    "\n",
    "print(f\"\\\\nCURVE EXTRACTION COMPLETE!\")\n",
    "print(f\"Curves Ready: {len(extracted_curves)}\")\n",
    "            \"\"\", globals())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Cell 8 execution failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def _execute_cell_10(self):\n",
    "        \"\"\"Execute Cell 10 - Quality Assessment\"\"\"\n",
    "        print(\"Running quality assessment from Cell 10...\")\n",
    "\n",
    "        try:\n",
    "            exec(\"\"\"\n",
    "print(\"CURVE EXTRACTION QUALITY ASSESSMENT\")\n",
    "\n",
    "def calculate_overall_quality_score(curve_data):\n",
    "    point_count = curve_data['point_count']\n",
    "    density_score = min(point_count / 200, 1.0)\n",
    "    overall_quality = density_score\n",
    "    return overall_quality, {'density_score': density_score}\n",
    "\n",
    "quality_assessment = {}\n",
    "overall_success_metrics = {'high_quality': 0, 'medium_quality': 0, 'low_quality': 0}\n",
    "\n",
    "print(\"\\\\nIndividual Curve Quality Analysis:\")\n",
    "\n",
    "for color_name, curve_data in extracted_curves.items():\n",
    "    overall_quality, quality_details = calculate_overall_quality_score(curve_data)\n",
    "\n",
    "    if overall_quality >= 0.75:\n",
    "        quality_level = \"HIGH\"\n",
    "        overall_success_metrics['high_quality'] += 1\n",
    "    elif overall_quality >= 0.5:\n",
    "        quality_level = \"MEDIUM\"\n",
    "        overall_success_metrics['medium_quality'] += 1\n",
    "    else:\n",
    "        quality_level = \"LOW\"\n",
    "        overall_success_metrics['low_quality'] += 1\n",
    "\n",
    "    quality_assessment[color_name] = {\n",
    "        'overall_quality': overall_quality,\n",
    "        'quality_level': quality_level\n",
    "    }\n",
    "\n",
    "    print(f\"\\\\n{color_name.upper()} CURVE - {quality_level} QUALITY\")\n",
    "    print(f\"Overall Score: {overall_quality:.2f}\")\n",
    "    print(f\"Points Extracted: {curve_data['point_count']}\")\n",
    "\n",
    "print(f\"\\\\nOVERALL EXTRACTION SUMMARY\")\n",
    "print(f\"High quality extractions: {overall_success_metrics['high_quality']}\")\n",
    "print(f\"Medium quality extractions: {overall_success_metrics['medium_quality']}\")\n",
    "print(f\"Low quality extractions: {overall_success_metrics['low_quality']}\")\n",
    "            \"\"\", globals())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Cell 10 execution failed: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def _trigger_color_detection(self):\n",
    "        print(\"Executing Cell 6 (Color Detection)...\")\n",
    "\n",
    "        try:\n",
    "            self._execute_cell_6()\n",
    "\n",
    "            if 'detected_colors' in globals():\n",
    "                return {\n",
    "                    'type': 'color_detection',\n",
    "                    'colors': detected_colors,\n",
    "                    'summary': f\"Found {len(detected_colors)} colors: {list(detected_colors.keys())}\",\n",
    "                    'cell_executed': '6'\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'type': 'color_detection',\n",
    "                    'colors': {},\n",
    "                    'summary': 'Color detection executed but no results found',\n",
    "                    'cell_executed': '6'\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'type': 'color_detection',\n",
    "                'colors': {},\n",
    "                'summary': f'Color detection failed: {str(e)}',\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def _trigger_excel_export(self, intent):\n",
    "        print(\"Executing Cell 12 (Excel Export)...\")\n",
    "\n",
    "        if 'extracted_curves' not in globals() or not extracted_curves:\n",
    "            return {\n",
    "                'type': 'excel_export',\n",
    "                'success': False,\n",
    "                'message': 'No curves available for export. Please extract curves first.',\n",
    "                'suggestion': 'Ask me to \"extract curves\" first.'\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            import __main__\n",
    "            __main__.excel_export_approved = True\n",
    "\n",
    "            exec(\"\"\"\n",
    "print(\"CELL 12 - EXCEL EXPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def convert_pixel_to_scientific(pixel_coords, axis_calibration):\n",
    "    x_pixel = axis_calibration['x_pixel']\n",
    "    y_pixel = axis_calibration['y_pixel']\n",
    "    x_real = axis_calibration['x_real']\n",
    "    y_real = axis_calibration['y_real']\n",
    "    x_scale = axis_calibration.get('x_scale', 'linear')\n",
    "    y_scale = axis_calibration.get('y_scale', 'linear')\n",
    "\n",
    "    scientific_x = []\n",
    "    scientific_y = []\n",
    "\n",
    "    for px, py in pixel_coords:\n",
    "        if x_scale == 'linear':\n",
    "            x_scientific = x_real[0] + (px - x_pixel[0]) * (x_real[1] - x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "        elif x_scale == 'log10':\n",
    "            log_x_real = [np.log10(max(x_real[0], 1e-10)), np.log10(max(x_real[1], 1e-10))]\n",
    "            log_x_interp = log_x_real[0] + (px - x_pixel[0]) * (log_x_real[1] - log_x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "            x_scientific = 10 ** log_x_interp\n",
    "        else:\n",
    "            x_scientific = px\n",
    "\n",
    "        if y_scale == 'linear':\n",
    "            y_scientific = y_real[0] + (py - y_pixel[0]) * (y_real[1] - y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "        elif y_scale == 'log10':\n",
    "            log_y_real = [np.log10(max(y_real[0], 1e-10)), np.log10(max(y_real[1], 1e-10))]\n",
    "            log_y_interp = log_y_real[0] + (py - y_pixel[0]) * (log_y_real[1] - log_y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "            y_scientific = 10 ** log_y_interp\n",
    "        else:\n",
    "            y_scientific = py\n",
    "\n",
    "        scientific_x.append(x_scientific)\n",
    "        scientific_y.append(y_scientific)\n",
    "\n",
    "    return np.array(scientific_x), np.array(scientific_y)\n",
    "\n",
    "def create_excel_export():\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    from google.colab import files\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"curve_data_{timestamp}.xlsx\"\n",
    "\n",
    "    print(f\"Creating Excel file: {filename}\")\n",
    "\n",
    "    # Use axis calibration from Cell 8\n",
    "    if 'axis_calibration' in globals():\n",
    "        axis_cal = axis_calibration\n",
    "    else:\n",
    "        # Fallback calibration\n",
    "        h, w = image_np.shape[:2]\n",
    "        axis_cal = {\n",
    "            'x_pixel': [int(w * 0.15), int(w * 0.90)],\n",
    "            'y_pixel': [int(h * 0.85), int(h * 0.10)],\n",
    "            'x_real': [0, 1000],\n",
    "            'y_real': [0.001, 10],\n",
    "            'x_scale': 'linear',\n",
    "            'y_scale': 'log10'\n",
    "        }\n",
    "\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        for color_name, curve_data in extracted_curves.items():\n",
    "            print(f\"Processing {color_name} curve...\")\n",
    "\n",
    "            x_scientific, y_scientific = convert_pixel_to_scientific(\n",
    "                curve_data['pixel_coordinates'],\n",
    "                axis_cal\n",
    "            )\n",
    "\n",
    "            simple_data = pd.DataFrame({\n",
    "                'X': x_scientific,\n",
    "                'Y': y_scientific\n",
    "            })\n",
    "\n",
    "            sheet_name = color_name[:31]\n",
    "            simple_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            print(f\"      {color_name}: {len(x_scientific)} data points exported\")\n",
    "\n",
    "    print(f\"\\\\nExcel file created successfully: {filename}\")\n",
    "\n",
    "    try:\n",
    "        files.download(filename)\n",
    "        print(f\"File download initiated successfully!\")\n",
    "        return True\n",
    "    except Exception as download_error:\n",
    "        print(f\"Auto-download failed, but file is saved: {filename}\")\n",
    "        return True\n",
    "\n",
    "excel_export_success = create_excel_export()\n",
    "            \"\"\", globals())\n",
    "\n",
    "            return {\n",
    "                'type': 'excel_export',\n",
    "                'success': True,\n",
    "                'message': 'Excel file created and download initiated!',\n",
    "                'curves_exported': list(extracted_curves.keys()),\n",
    "                'total_points': sum(curve['point_count'] for curve in extracted_curves.values()),\n",
    "                'cell_executed': '12'\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'type': 'excel_export',\n",
    "                'success': False,\n",
    "                'message': f'Excel export error: {str(e)}',\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def _analyze_axes(self, intent):\n",
    "        return {\n",
    "            'type': 'axis_analysis',\n",
    "            'result': 'Axis analysis available through curve extraction pipeline.',\n",
    "            'suggestion': 'Ask to \"extract curves\" for complete graph analysis including axes.'\n",
    "        }\n",
    "\n",
    "    def _handle_coordinates(self, intent):\n",
    "        print(\"ðŸŽ¯ Analyzing graph coordinates...\")\n",
    "\n",
    "        if 'extracted_curves' not in globals() or not extracted_curves:\n",
    "            print(\"ðŸ“Š No curves extracted yet. Running extraction pipeline first...\")\n",
    "\n",
    "            extraction_result = self._trigger_extraction_pipeline({\n",
    "                'type': 'curve_extraction',\n",
    "                'colors': [],\n",
    "                'mode': 'auto'\n",
    "            })\n",
    "\n",
    "            if not extraction_result.get('pipeline_executed') or not extracted_curves:\n",
    "                return {\n",
    "                    'type': 'coordinates',\n",
    "                    'result': 'Unable to extract coordinates. No curves were found in the image.',\n",
    "                    'suggestion': 'Check image quality or try specifying specific colors to extract.'\n",
    "                }\n",
    "\n",
    "        def get_smart_calibration():\n",
    "            if 'axis_calibration' in globals():\n",
    "                cal = axis_calibration.copy()\n",
    "                height, width = self.image.shape[:2]\n",
    "                if 'x_pixel' not in cal or 'y_pixel' not in cal:\n",
    "                    cal['x_pixel'] = [int(width * 0.15), int(width * 0.85)]\n",
    "                    cal['y_pixel'] = [int(height * 0.85), int(height * 0.15)]\n",
    "                return cal\n",
    "            else:\n",
    "                height, width = self.image.shape[:2]\n",
    "                return {\n",
    "                    'x_pixel': [int(width * 0.15), int(width * 0.85)],\n",
    "                    'y_pixel': [int(height * 0.85), int(height * 0.15)],\n",
    "                    'x_real': [0, 100],\n",
    "                    'y_real': [0, 100],\n",
    "                    'x_scale': 'linear',\n",
    "                    'y_scale': 'linear'\n",
    "                }\n",
    "\n",
    "        cal = get_smart_calibration()\n",
    "\n",
    "        coordinate_analysis = []\n",
    "\n",
    "        for color_name, curve_data in extracted_curves.items():\n",
    "            pixel_coords = curve_data['pixel_coordinates']\n",
    "\n",
    "            if len(pixel_coords) == 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                x_sci, y_sci = self._convert_to_scientific_coords(pixel_coords, cal)\n",
    "            except Exception as e:\n",
    "                print(f\"Conversion failed for {color_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            x_min, x_max = np.min(x_sci), np.max(x_sci)\n",
    "            y_min, y_max = np.min(y_sci), np.max(y_sci)\n",
    "\n",
    "            if len(y_sci) > 10:\n",
    "                quarter = len(y_sci) // 4\n",
    "                start_y = np.median(y_sci[:quarter])\n",
    "                end_y = np.median(y_sci[-quarter:])\n",
    "                y_range = y_max - y_min\n",
    "                y_change = abs(end_y - start_y)\n",
    "\n",
    "                relative_change = y_change / max(y_range, 1e-10)\n",
    "                growth_ratio = end_y / max(start_y, 1e-10) if start_y != 0 else float('inf')\n",
    "\n",
    "                if relative_change < 0.15:\n",
    "                    trend = \"stays nearly flat\"\n",
    "                    trend_detail = f\"around ~{np.median(y_sci):.2f}\"\n",
    "                elif growth_ratio > 3 or relative_change > 0.5:\n",
    "                    trend = \"rises steeply\"\n",
    "                    trend_detail = \"\"\n",
    "                elif growth_ratio > 1.3 or relative_change > 0.25:\n",
    "                    trend = \"rises gradually\"\n",
    "                    trend_detail = \"\"\n",
    "                elif growth_ratio < 0.7:\n",
    "                    trend = \"decreases\"\n",
    "                    trend_detail = \"\"\n",
    "                else:\n",
    "                    trend = \"shows moderate variation\"\n",
    "                    trend_detail = \"\"\n",
    "            else:\n",
    "                trend = \"has limited data points\"\n",
    "                trend_detail = \"\"\n",
    "\n",
    "            curve_desc = f\"The {color_name} curve\"\n",
    "\n",
    "            if cal.get('y_scale') == 'log10':\n",
    "                if y_min < 0.01:\n",
    "                    y_min_str = f\"{y_min:.2e}\"\n",
    "                else:\n",
    "                    y_min_str = f\"{y_min:.1f}\"\n",
    "\n",
    "                if y_max < 0.01:\n",
    "                    y_max_str = f\"{y_max:.2e}\"\n",
    "                else:\n",
    "                    y_max_str = f\"{y_max:.1f}\"\n",
    "            else:\n",
    "                y_min_str = f\"{y_min:.2f}\"\n",
    "                y_max_str = f\"{y_max:.2f}\"\n",
    "\n",
    "            x_min_str = f\"{x_min:.1f}\"\n",
    "            x_max_str = f\"{x_max:.1f}\"\n",
    "\n",
    "            if trend_detail:\n",
    "                coord_desc = f\"{curve_desc} {trend} {trend_detail} from {x_min:.1f} to {x_max:.1f}.\"\n",
    "            else:\n",
    "                coord_desc = f\"{curve_desc} starts at around ({x_min_str}, {y_min_str}), {trend}, and reaches about ({x_max_str}, {y_max_str}).\"\n",
    "\n",
    "            coordinate_analysis.append(coord_desc)\n",
    "\n",
    "        if not coordinate_analysis:\n",
    "            return {\n",
    "                'type': 'coordinates',\n",
    "                'result': 'No curve coordinates could be analyzed.',\n",
    "                'suggestion': 'Try extracting specific colors or check image quality.'\n",
    "            }\n",
    "\n",
    "        full_analysis = \"\\n\".join(coordinate_analysis)\n",
    "        full_analysis += \"\\n\\nIf you'd like, I can extract exact coordinate pairs from each curve and output them as CSV or plot them separately.\"\n",
    "\n",
    "        return {\n",
    "            'type': 'coordinates',\n",
    "            'result': full_analysis,\n",
    "            'curves_analyzed': len(coordinate_analysis),\n",
    "            'total_points': sum(curve['point_count'] for curve in extracted_curves.values())\n",
    "        }\n",
    "\n",
    "    def _convert_to_scientific_coords(self, pixel_coords, axis_calibration):\n",
    "        x_pixel = axis_calibration['x_pixel']\n",
    "        y_pixel = axis_calibration['y_pixel']\n",
    "        x_real = axis_calibration['x_real']\n",
    "        y_real = axis_calibration['y_real']\n",
    "        x_scale = axis_calibration.get('x_scale', 'linear')\n",
    "        y_scale = axis_calibration.get('y_scale', 'linear')\n",
    "\n",
    "        scientific_x = []\n",
    "        scientific_y = []\n",
    "\n",
    "        for px, py in pixel_coords:\n",
    "            if x_scale == 'linear':\n",
    "                x_sci = x_real[0] + (px - x_pixel[0]) * (x_real[1] - x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "            elif x_scale == 'log10':\n",
    "                log_x_real = [np.log10(max(x_real[0], 1e-10)), np.log10(max(x_real[1], 1e-10))]\n",
    "                log_x_interp = log_x_real[0] + (px - x_pixel[0]) * (log_x_real[1] - log_x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "                x_sci = 10 ** log_x_interp\n",
    "            else:\n",
    "                x_sci = px\n",
    "\n",
    "            if y_scale == 'linear':\n",
    "                y_sci = y_real[0] + (py - y_pixel[0]) * (y_real[1] - y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "            elif y_scale == 'log10':\n",
    "                log_y_real = [np.log10(max(y_real[0], 1e-10)), np.log10(max(y_real[1], 1e-10))]\n",
    "                log_y_interp = log_y_real[0] + (py - y_pixel[0]) * (log_y_real[1] - log_y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "                y_sci = 10 ** log_y_interp\n",
    "            else:\n",
    "                y_sci = py\n",
    "\n",
    "            scientific_x.append(x_sci)\n",
    "            scientific_y.append(y_sci)\n",
    "\n",
    "        return np.array(scientific_x), np.array(scientific_y)\n",
    "\n",
    "    def _general_analysis(self, intent):\n",
    "        if self.gpt_available:\n",
    "            return self._ai_general_analysis(intent)\n",
    "        else:\n",
    "            return {\n",
    "                'type': 'general_visual',\n",
    "                'result': 'Basic image loaded. Ask to extract curves, detect colors, or create excel files.',\n",
    "                'note': 'For detailed AI analysis, enable GPT capability.'\n",
    "            }\n",
    "\n",
    "    def _ai_general_analysis(self, intent):\n",
    "        print(\"Analyzing graph with AI...\")\n",
    "\n",
    "        img_buffer = io.BytesIO()\n",
    "        Image.fromarray(self.image).save(img_buffer, format='PNG')\n",
    "        img_base64 = base64.b64encode(img_buffer.getvalue()).decode()\n",
    "\n",
    "        analysis_prompt = \"\"\"\n",
    "Analyze this scientific graph and provide a clear, structured description.\n",
    "\n",
    "Format your response as natural prose with these sections:\n",
    "\n",
    "**Overview**\n",
    "Brief description of the graph type and what it shows.\n",
    "\n",
    "**Axes**\n",
    "* X-axis: units, range, scale type\n",
    "* Y-axis: units, range, scale type\n",
    "\n",
    "**Curves/Data**\n",
    "For each visible curve/line/data series, describe:\n",
    "* Color and line style\n",
    "* What it represents (from legend if visible)\n",
    "* General trend or behavior\n",
    "\n",
    "**Key Insights**\n",
    "Notable patterns, relationships, or scientific conclusions visible in the data.\n",
    "\n",
    "Be specific about numerical ranges, units, and trends you can observe.\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            import openai\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": analysis_prompt},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": \"What type of graph is this? Provide detailed analysis.\"},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.1\n",
    "            )\n",
    "\n",
    "            analysis_text = response.choices[0].message.content\n",
    "\n",
    "            return {\n",
    "                'type': 'general_visual',\n",
    "                'result': analysis_text,\n",
    "                'method': 'ai_analysis'\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"AI analysis failed: {str(e)}\")\n",
    "            return {\n",
    "                'type': 'general_visual',\n",
    "                'result': f'AI analysis unavailable. Basic observation: Scientific graph with axes and multiple curves.',\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def _handle_other(self, intent):\n",
    "        return {\n",
    "            'type': 'unknown',\n",
    "            'result': 'Request not recognized. Try: \"extract curves\", \"what colors are available\", \"analyze this graph\", or \"create excel file\".',\n",
    "            'suggestions': ['extract black curve', 'what colors are available', 'analyze this graph', 'create excel file']\n",
    "        }\n",
    "\n",
    "print(\"Initializing intelligent router...\")\n",
    "\n",
    "if 'image_np' not in globals():\n",
    "    print(\"No image found. Please run image upload cell first.\")\n",
    "    router = None\n",
    "elif 'gpt_available' not in globals():\n",
    "    print(\"No GPT configuration found. Please run setup cells first.\")\n",
    "    print(\"Will use computer vision only (limited analysis).\")\n",
    "    gpt_available = False\n",
    "    router = GraphAnalysisRouter(image_np, gpt_available)\n",
    "else:\n",
    "    if gpt_available and not hasattr(openai, 'api_key'):\n",
    "        print(\"GPT marked available but no API key found. Using CV-only mode.\")\n",
    "        gpt_available = False\n",
    "\n",
    "    router = GraphAnalysisRouter(image_np, gpt_available)\n",
    "\n",
    "if router is not None:\n",
    "    while True:\n",
    "        user_request = input(\"\\nWhat would you like to do with this graph? (or 'done' to finish): \").strip()\n",
    "\n",
    "        if user_request.lower() in ['done', 'stop', 'quit', 'exit']:\n",
    "            print(\"Stopping now.\")\n",
    "            break\n",
    "\n",
    "        if not user_request:\n",
    "            user_request = \"detect available colors and extract all curves\"\n",
    "            print(f\"Using default: {user_request}\")\n",
    "\n",
    "        result = router.route_and_execute(user_request)\n",
    "\n",
    "        print(f\"\\nRESULT:\")\n",
    "        if result.get('status') == 'clarification_needed':\n",
    "            print(f\"{result['question']}\")\n",
    "            clarification = input(\" \").strip()\n",
    "            if clarification:\n",
    "                intent = router._parse_intent(user_request)\n",
    "                intent['coord_type'] = clarification\n",
    "                result = router._handle_coordinates(intent)\n",
    "                print(f\"{result.get('result', 'Analysis complete')}\")\n",
    "        else:\n",
    "            if result['type'] == 'general_visual' and 'result' in result:\n",
    "                print(result['result'])\n",
    "            elif result['type'] == 'excel_export':\n",
    "                if result['success']:\n",
    "                    print(f\"{result['message']}\")\n",
    "                    if 'curves_exported' in result:\n",
    "                        print(f\"Exported curves: {', '.join(result['curves_exported'])}\")\n",
    "                        print(f\"Total data points: {result['total_points']}\")\n",
    "                else:\n",
    "                    print(f\"{result['message']}\")\n",
    "                    if 'suggestion' in result:\n",
    "                        print(f\"{result['suggestion']}\")\n",
    "            elif 'result' in result:\n",
    "                print(result['result'])\n",
    "            elif 'summary' in result:\n",
    "                print(f\"{result['summary']}\")\n",
    "            else:\n",
    "                print(\"Analysis complete\")\n",
    "\n",
    "            if 'cells_executed' in result:\n",
    "                print(f\"Cells executed: {', '.join(result['cells_executed'])}\")\n",
    "            elif 'cell_executed' in result:\n",
    "                print(f\"Cell executed: {result['cell_executed']}\")\n",
    "\n",
    "            if result['type'] == 'curve_extraction' and result.get('pipeline_executed'):\n",
    "                print(f\"{result.get('next_step', 'Analysis complete')}\")\n",
    "else:\n",
    "    print(\"Cannot initialize router. Please check setup and try again.\")\n",
    "\n",
    "print(f\"\\nAnalysis session complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MshmXmCFHfM1"
   },
   "outputs": [],
   "source": [
    "#CELL 6\n",
    "print(\"SCANNING IMAGE FOR AVAILABLE COLORS...\")\n",
    "print(\"Analyzing pixel distributions and color presence...\")\n",
    "\n",
    "hsv_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "detected_colors = {}\n",
    "min_pixel_threshold = 50\n",
    "\n",
    "def analyze_color_presence(hsv_img, color_name, color_range):\n",
    "    lower_hsv, upper_hsv = color_range\n",
    "    lower = np.array(lower_hsv)\n",
    "    upper = np.array(upper_hsv)\n",
    "\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    pixel_count = np.count_nonzero(mask)\n",
    "\n",
    "    if pixel_count > 0:\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "\n",
    "        if num_labels > 1:\n",
    "            largest_component = np.max(stats[1:, cv2.CC_STAT_AREA])\n",
    "            distribution_quality = largest_component / pixel_count\n",
    "        else:\n",
    "            distribution_quality = 0\n",
    "    else:\n",
    "        distribution_quality = 0\n",
    "\n",
    "    return {\n",
    "        'pixel_count': pixel_count,\n",
    "        'distribution_quality': distribution_quality,\n",
    "        'mask': mask,\n",
    "        'present': pixel_count > min_pixel_threshold\n",
    "    }\n",
    "\n",
    "print(\"\\nColor Detection Results:\")\n",
    "\n",
    "for color_name, color_range in selected_colors.items():\n",
    "    analysis = analyze_color_presence(hsv_image, color_name, color_range)\n",
    "\n",
    "    if analysis['present']:\n",
    "        detected_colors[color_name] = {\n",
    "            'range': color_range,\n",
    "            'pixel_count': analysis['pixel_count'],\n",
    "            'quality': analysis['distribution_quality'],\n",
    "            'mask': analysis['mask']\n",
    "        }\n",
    "\n",
    "        quality_desc = \"High\" if analysis['distribution_quality'] > 0.3 else \"Medium\" if analysis['distribution_quality'] > 0.1 else \"Low\"\n",
    "        print(f\"{color_name:8}: {analysis['pixel_count']:5} pixels (Quality: {quality_desc})\")\n",
    "    else:\n",
    "        print(f\"{color_name:8}: {analysis['pixel_count']:5} pixels (Below threshold)\")\n",
    "\n",
    "if detected_colors:\n",
    "    print(f\"\\nFound {len(detected_colors)} processable colors\")\n",
    "else:\n",
    "    print(\"\\nNo colors detected above threshold!\")\n",
    "    print(\"Try adjusting color selection or check image quality\")\n",
    "\n",
    "print(f\"\\nSummary: {len(detected_colors)} colors ready for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGkMY06MHkgj"
   },
   "outputs": [],
   "source": [
    "#CELL 7\n",
    "print(\"DETECTING AND REMOVING GRAPH INFRASTRUCTURE...\")\n",
    "print(\"Identifying text, axes, grid lines, and other non-curve elements...\")\n",
    "\n",
    "def detect_text_regions(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    text_mask = np.zeros_like(gray)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if 10 < area < 500 and 0.2 < h/w < 5:\n",
    "            cv2.fillPoly(text_mask, [contour], 255)\n",
    "    return text_mask\n",
    "\n",
    "def detect_straight_lines(image, min_line_length=50):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100,\n",
    "                           minLineLength=min_line_length, maxLineGap=10)\n",
    "    line_mask = np.zeros_like(gray)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "            angle = np.arctan2(y2-y1, x2-x1) * 180 / np.pi\n",
    "            is_horizontal = abs(angle) < 5 or abs(angle-180) < 5\n",
    "            is_vertical = abs(angle-90) < 5 or abs(angle+90) < 5\n",
    "            if length > min_line_length * 2 or is_horizontal or is_vertical:\n",
    "                cv2.line(line_mask, (x1, y1), (x2, y2), 255, 3)\n",
    "    return line_mask\n",
    "\n",
    "print(\"Detecting text regions...\")\n",
    "text_mask = detect_text_regions(image_np)\n",
    "\n",
    "print(\"Detecting straight lines (axes, grids)...\")\n",
    "line_mask = detect_straight_lines(image_np)\n",
    "\n",
    "infrastructure_mask = cv2.bitwise_or(text_mask, line_mask)\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "infrastructure_mask = cv2.morphologyEx(infrastructure_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cleaned_image = image_np.copy()\n",
    "infrastructure_coords = np.where(infrastructure_mask == 255)\n",
    "cleaned_image[infrastructure_coords] = [255, 255, 255]\n",
    "\n",
    "print(\"Infrastructure removal complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqGrRpkDHp5d"
   },
   "outputs": [],
   "source": [
    "#CELL 8\n",
    "print(\"INTELLIGENT CURVE EXTRACTION - RESPECTING USER PREFERENCES\")\n",
    "print(\"READING USER PREFERENCES FROM INTERACTIVE SESSION...\")\n",
    "\n",
    "if 'user_extraction_mode' in globals():\n",
    "    extraction_mode = user_extraction_mode\n",
    "    requested_colors = user_requested_colors if 'user_requested_colors' in globals() else []\n",
    "    extraction_instructions = user_extraction_instructions if 'user_extraction_instructions' in globals() else \"\"\n",
    "    nlp_connected = True\n",
    "    print(\"Natural Language Processing connection: ACTIVE\")\n",
    "else:\n",
    "    extraction_mode = \"auto\"\n",
    "    requested_colors = []\n",
    "    extraction_instructions = \"\"\n",
    "    nlp_connected = False\n",
    "    print(\"Natural Language Processing connection: MISSING\")\n",
    "\n",
    "print(f\"\\nUSER PREFERENCE SUMMARY:\")\n",
    "print(f\"\\tMode: {extraction_mode.upper()}\")\n",
    "print(f\"\\tRequested Colors: {requested_colors if requested_colors else 'All detected'}\")\n",
    "print(f\"\\tUser Instructions: '{extraction_instructions}'\" if extraction_instructions else \"No specific instructions\")\n",
    "print(f\"\\tNLP Connected: {'YES' if nlp_connected else 'NO'}\")\n",
    "\n",
    "print(f\"\\nFILTERING COLORS BASED ON USER REQUEST...\")\n",
    "print(f\"Original detected colors: {list(detected_colors.keys())}\")\n",
    "\n",
    "def filter_colors_by_user_request(detected_colors, mode, requested_colors):\n",
    "    \"\"\"Filter colors based on user preferences\"\"\"\n",
    "\n",
    "    if mode == \"auto\":\n",
    "        filtered_colors = detected_colors.copy()\n",
    "        print(f\"AUTO MODE: Using all {len(filtered_colors)} detected colors\")\n",
    "        return filtered_colors\n",
    "\n",
    "    elif mode == \"all\":\n",
    "        filtered_colors = detected_colors.copy()\n",
    "        print(f\"ALL MODE: User requested all colors ({len(filtered_colors)} detected)\")\n",
    "        return filtered_colors\n",
    "\n",
    "    elif mode == \"selective\":\n",
    "        print(f\"SELECTIVE MODE: Processing specific user requests...\")\n",
    "        filtered_colors = {}\n",
    "\n",
    "        for color in requested_colors:\n",
    "            if color in detected_colors:\n",
    "                filtered_colors[color] = detected_colors[color]\n",
    "                print(f\"{color.upper()}: Found and will be extracted ({detected_colors[color]['pixel_count']} pixels)\")\n",
    "            else:\n",
    "                print(f\"{color.upper()}: Requested but not detected in image\")\n",
    "                print(f\"This color may not be present or may need different detection parameters\")\n",
    "\n",
    "        if not filtered_colors:\n",
    "            print(f\"WARNING: No requested colors were found!\")\n",
    "            print(f\"FALLBACK: Will attempt manual detection for requested colors...\")\n",
    "\n",
    "            for color in requested_colors:\n",
    "                if color in selected_colors:  # Use predefined color ranges\n",
    "                    print(f\"Attempting manual detection for {color.upper()}...\")\n",
    "\n",
    "                    hsv_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)\n",
    "                    color_range = selected_colors[color]\n",
    "                    lower_hsv, upper_hsv = color_range\n",
    "\n",
    "                    if color == 'black':\n",
    "                        # More restrictive black detection to avoid red bars\n",
    "                        expanded_lower = [0, 0, 0]\n",
    "                        expanded_upper = [180, 50, 80]  # KEY FIX: Much tighter limits\n",
    "                    else:\n",
    "                        expanded_lower = [max(0, lower_hsv[0]-20), max(0, lower_hsv[1]-40), max(0, lower_hsv[2]-40)]\n",
    "                        expanded_upper = [min(180, upper_hsv[0]+20), min(255, upper_hsv[1]+40), min(255, upper_hsv[2]+40)]\n",
    "\n",
    "                    mask = cv2.inRange(hsv_image, np.array(expanded_lower), np.array(expanded_upper))\n",
    "                    pixel_count = np.count_nonzero(mask)\n",
    "\n",
    "                    min_threshold = 20\n",
    "\n",
    "                    if pixel_count >= min_threshold:\n",
    "                        filtered_colors[color] = {\n",
    "                            'range': color_range,\n",
    "                            'pixel_count': pixel_count,\n",
    "                            'quality': 0.8,\n",
    "                            'mask': mask\n",
    "                        }\n",
    "                        print(f\"{color.upper()}: Manual detection successful ({pixel_count} pixels)\")\n",
    "                    else:\n",
    "                        print(f\"{color.upper()}: Manual detection failed ({pixel_count} pixels, needed {min_threshold})\")\n",
    "\n",
    "        print(f\"SELECTIVE RESULT: Will extract {len(filtered_colors)} colors: {list(filtered_colors.keys())}\")\n",
    "        return filtered_colors\n",
    "\n",
    "    else:\n",
    "        print(f\"UNKNOWN MODE '{mode}': Defaulting to all detected colors\")\n",
    "        return detected_colors.copy()\n",
    "\n",
    "processing_colors = filter_colors_by_user_request(detected_colors, extraction_mode, requested_colors)\n",
    "\n",
    "if not processing_colors:\n",
    "    print(f\"\\nCRITICAL ERROR: No colors available for extraction!\")\n",
    "    print(f\"You requested: {requested_colors if requested_colors else 'Auto-detect'}\")\n",
    "    print(f\"Available colors: {list(detected_colors.keys())}\")\n",
    "    print(f\"Suggestions:\")\n",
    "    print(f\"- Check if the requested color is visible in the image\")\n",
    "    print(f\"- Try using 'auto' mode to see what colors are detected\")\n",
    "    print(f\"- Verify the color name spelling\")\n",
    "\n",
    "    # Emergency fallback\n",
    "    print(f\"EMERGENCY FALLBACK: Using all detected colors to avoid total failure...\")\n",
    "    processing_colors = detected_colors.copy()\n",
    "\n",
    "print(f\"\\nFINAL PROCESSING LIST: {list(processing_colors.keys())}\")\n",
    "print(f\"\\nSTARTING EXTRACTION OF USER-REQUESTED COLORS...\")\n",
    "\n",
    "def trace_black_curve_enhanced(image_np, graph_bounds, roi=None, threshold_method='black_specific',\n",
    "                              canny_params=(30, 80), min_pixels=100):\n",
    "    \"\"\"\n",
    "    Enhanced black curve extraction with histogram bar filtering\n",
    "    KEY IMPROVEMENTS:\n",
    "    - Stricter black color detection\n",
    "    - Vertical structure removal (removes histogram bars!)\n",
    "    - Curve-focused component scoring\n",
    "    \"\"\"\n",
    "\n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Set up ROI to focus on data area\n",
    "    if roi is None and graph_bounds is not None:\n",
    "        left, top, right, bottom = graph_bounds\n",
    "        margin = 15\n",
    "        roi = (top + margin, bottom - margin, left + margin, right - margin)\n",
    "        print(f\"\\tUsing data-focused ROI to avoid borders: {roi}\")\n",
    "\n",
    "    if roi is not None:\n",
    "        y1, y2, x1, x2 = roi\n",
    "        roi_img = gray[y1:y2, x1:x2]\n",
    "        roi_rgb = image_np[y1:y2, x1:x2]\n",
    "        roi_offset = (x1, y1)\n",
    "    else:\n",
    "        roi_img = gray.copy()\n",
    "        roi_rgb = image_np.copy()\n",
    "        roi_offset = (0, 0)\n",
    "\n",
    "    if threshold_method == 'black_specific':\n",
    "        # CRITICAL FIX: Much stricter black detection to avoid red histogram bars\n",
    "        hsv = cv2.cvtColor(roi_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        lower_black = np.array([0, 0, 0])\n",
    "        upper_black = np.array([180, 50, 80])  # KEY FIX: Tighter saturation/value limits\n",
    "        black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "        # Secondary threshold for robustness\n",
    "        _, gray_thresh = cv2.threshold(roi_img, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Combine both approaches\n",
    "        edges = cv2.bitwise_or(black_mask, gray_thresh)\n",
    "\n",
    "        # Clean up noise\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "        edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    elif threshold_method == 'canny':\n",
    "        edges = cv2.Canny(cv2.GaussianBlur(roi_img, (5, 5), 0),\n",
    "                          canny_params[0], canny_params[1])\n",
    "    elif threshold_method == 'binary':\n",
    "        _, edges = cv2.threshold(roi_img, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    else:\n",
    "        edges = cv2.adaptiveThreshold(roi_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # CRITICAL FIX: Remove vertical structures (histogram bars!)\n",
    "    kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))\n",
    "    kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 20))\n",
    "\n",
    "    horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_h)\n",
    "    vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_v)\n",
    "\n",
    "    # Remove both horizontal and vertical line structures\n",
    "    edges = cv2.subtract(edges, horizontal_lines)\n",
    "    edges = cv2.subtract(edges, vertical_lines)  # This removes histogram bars!\n",
    "\n",
    "    # Skeletonize for clean curve representation\n",
    "    thin = skeletonize(edges > 0)\n",
    "\n",
    "    # Find connected components\n",
    "    num_lbl, lbl, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        thin.astype(np.uint8), connectivity=8\n",
    "    )\n",
    "    if num_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    # INTELLIGENT COMPONENT SCORING - Prefers curve-like structures\n",
    "    best_component = None\n",
    "    best_score = 0\n",
    "\n",
    "    for i in range(1, num_lbl):\n",
    "        if stats[i, cv2.CC_STAT_AREA] < min_pixels:\n",
    "            continue\n",
    "\n",
    "        mask = (lbl == i)\n",
    "        ys, xs = np.where(mask)\n",
    "        pts = np.column_stack([xs, ys])\n",
    "\n",
    "        if len(pts) < 20:\n",
    "            continue\n",
    "\n",
    "        pts = pts[np.argsort(pts[:, 0])]\n",
    "\n",
    "        x_span = np.max(pts[:, 0]) - np.min(pts[:, 0])\n",
    "        y_span = np.max(pts[:, 1]) - np.min(pts[:, 1])\n",
    "\n",
    "        # Filter out narrow vertical structures (like remaining histogram bars)\n",
    "        if x_span < 100 or y_span < 30:\n",
    "            continue\n",
    "\n",
    "        # Analyze curve characteristics\n",
    "        x_sorted_indices = np.argsort(pts[:, 0])\n",
    "        x_vals = pts[x_sorted_indices, 0]\n",
    "        y_vals = pts[x_sorted_indices, 1]\n",
    "\n",
    "        # Score based on curve-like properties\n",
    "        trend_score = 0\n",
    "        if len(y_vals) > 10:\n",
    "            mid_point = len(y_vals) // 2\n",
    "            y_start = np.mean(y_vals[:mid_point//2]) if mid_point//2 > 0 else y_vals[0]\n",
    "            y_end = np.mean(y_vals[-mid_point//2:]) if mid_point//2 > 0 else y_vals[-1]\n",
    "\n",
    "            # Prefer upward trends (typical for scientific curves)\n",
    "            if y_end > y_start:\n",
    "                trend_score += 2\n",
    "\n",
    "            # Analyze curvature vs straight lines\n",
    "            if len(pts) > 10:\n",
    "                direct_distance = np.sqrt((pts[-1, 0] - pts[0, 0])**2 + (pts[-1, 1] - pts[0, 1])**2)\n",
    "                actual_distance = np.sum(np.sqrt(np.diff(pts[:, 0])**2 + np.diff(pts[:, 1])**2))\n",
    "                curvature_ratio = actual_distance / max(direct_distance, 1)\n",
    "\n",
    "                # Prefer curved over straight lines\n",
    "                if curvature_ratio > 1.2:\n",
    "                    trend_score += 1\n",
    "\n",
    "        # Prefer components in lower part of image (typical for data curves)\n",
    "        avg_y = np.mean(pts[:, 1])\n",
    "        if roi is None:\n",
    "            img_height = gray.shape[0]\n",
    "        else:\n",
    "            img_height = roi_img.shape[0]\n",
    "\n",
    "        if avg_y > img_height * 0.4:\n",
    "            trend_score += 1\n",
    "\n",
    "        # Calculate final score favoring wide, horizontal, curve-like structures\n",
    "        aspect_ratio = x_span / max(y_span, 1)\n",
    "        area_score = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "        score = area_score * aspect_ratio * (1 + trend_score)\n",
    "\n",
    "        print(f\"\\tComponent {i}: area={area_score}, ratio={aspect_ratio:.1f}, trend={trend_score}, score={score:.1f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_component = i\n",
    "\n",
    "    if best_component is None:\n",
    "        print(\"      No suitable curved line found\")\n",
    "        return None\n",
    "\n",
    "    # Extract the best component\n",
    "    mask = (lbl == best_component)\n",
    "    ys, xs = np.where(mask)\n",
    "    pts = np.column_stack([xs, ys])\n",
    "\n",
    "    # Sort by x-coordinate\n",
    "    pts = pts[np.argsort(pts[:, 0])]\n",
    "\n",
    "    # Handle multiple y-values for same x (take median)\n",
    "    unique_x = np.unique(pts[:, 0])\n",
    "    if len(unique_x) < len(pts):\n",
    "        new_pts = []\n",
    "        for ux in unique_x:\n",
    "            y_vals = pts[pts[:, 0] == ux, 1]\n",
    "            median_y = np.median(y_vals)\n",
    "            new_pts.append([ux, median_y])\n",
    "        pts = np.array(new_pts)\n",
    "\n",
    "    # Convert back to full image coordinates\n",
    "    pts[:, 0] += roi_offset[0]\n",
    "    pts[:, 1] += roi_offset[1]\n",
    "\n",
    "    print(f\"      Selected component {best_component} with score {best_score:.1f}\")\n",
    "    print(f\"      Curve spans: X={np.min(pts[:, 0]):.0f}-{np.max(pts[:, 0]):.0f}, Y={np.min(pts[:, 1]):.0f}-{np.max(pts[:, 1]):.0f}\")\n",
    "    return pts\n",
    "\n",
    "def extract_simple_curve(image_np, graph_bounds, color_name, color_range):\n",
    "    \"\"\"Extract non-black curves with improved ROI handling\"\"\"\n",
    "\n",
    "    left, top, right, bottom = graph_bounds\n",
    "\n",
    "    # KEY FIX: Exclude legend and border areas where artifacts might cluster\n",
    "    legend_margin = 80\n",
    "    border_margin = 20\n",
    "\n",
    "    data_left = left + border_margin\n",
    "    data_top = top + border_margin\n",
    "    data_right = right - legend_margin  # Avoid right-side legend area\n",
    "    data_bottom = bottom - border_margin\n",
    "\n",
    "    data_roi = image_np[data_top:data_bottom, data_left:data_right]\n",
    "    print(f\"\\tData ROI (excludes legend): {data_roi.shape}\")\n",
    "\n",
    "    # Color detection\n",
    "    hsv_roi = cv2.cvtColor(data_roi, cv2.COLOR_RGB2HSV)\n",
    "    lower_hsv, upper_hsv = color_range\n",
    "    lower = np.array(lower_hsv)\n",
    "    upper = np.array(upper_hsv)\n",
    "\n",
    "    mask = cv2.inRange(hsv_roi, lower, upper)\n",
    "\n",
    "    # Clean up noise\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Skeletonize\n",
    "    skeleton = skeletonize(mask > 0)\n",
    "    coords = np.column_stack(np.where(skeleton.T))\n",
    "\n",
    "    if len(coords) == 0:\n",
    "        print(f\"\\tNo skeleton points found for {color_name}\")\n",
    "        return None\n",
    "\n",
    "    # Sort by x-coordinate\n",
    "    coords = coords[coords[:, 0].argsort()]\n",
    "\n",
    "    # Handle multiple points at same x-coordinate (take median y)\n",
    "    unique_coords = []\n",
    "    current_x = None\n",
    "    y_values = []\n",
    "\n",
    "    for x, y in coords:\n",
    "        if current_x is None or x != current_x:\n",
    "            if current_x is not None:\n",
    "                avg_y = np.median(y_values)\n",
    "                unique_coords.append([current_x, avg_y])\n",
    "            current_x = x\n",
    "            y_values = [y]\n",
    "        else:\n",
    "            y_values.append(y)\n",
    "\n",
    "    if current_x is not None:\n",
    "        avg_y = np.median(y_values)\n",
    "        unique_coords.append([current_x, avg_y])\n",
    "\n",
    "    if len(unique_coords) == 0:\n",
    "        print(f\"\\tNo unique coordinates for {color_name}\")\n",
    "        return None\n",
    "\n",
    "    final_coords = np.array(unique_coords)\n",
    "    # Convert back to full image coordinates\n",
    "    final_coords[:, 0] += data_left\n",
    "    final_coords[:, 1] += data_top\n",
    "\n",
    "    print(f\"      {color_name}: {len(final_coords)} points extracted\")\n",
    "    print(f\"      Range: X={np.min(final_coords[:, 0]):.0f}-{np.max(final_coords[:, 0]):.0f}, Y={np.min(final_coords[:, 1]):.0f}-{np.max(final_coords[:, 1]):.0f}\")\n",
    "\n",
    "    return final_coords\n",
    "\n",
    "# Main extraction loop\n",
    "validated_colors = {}\n",
    "extraction_results = {\n",
    "    'requested': list(processing_colors.keys()),\n",
    "    'successful': [],\n",
    "    'failed': [],\n",
    "    'total_points': 0\n",
    "}\n",
    "\n",
    "print(f\"\\nEXTRACTING CURVES FOR: {', '.join(processing_colors.keys())}\")\n",
    "\n",
    "for color_name, color_data in processing_colors.items():\n",
    "    print(f\"\\nPROCESSING '{color_name.upper()}' (User Requested: {'YES' if color_name in requested_colors or extraction_mode != 'selective' else 'NO'})...\")\n",
    "\n",
    "    if color_name == 'black':\n",
    "        print(\"\\tUSING ADVANCED BLACK CURVE ALGORITHM...\")\n",
    "\n",
    "        curve_points = trace_black_curve_enhanced(\n",
    "            image_np,\n",
    "            axis_calibration['bounds']\n",
    "        )\n",
    "\n",
    "        if curve_points is not None:\n",
    "            # Create visualization mask\n",
    "            combined_mask = np.zeros_like(color_data['mask'])\n",
    "\n",
    "            # Draw curve as lines\n",
    "            for i in range(len(curve_points)-1):\n",
    "                pt1 = (int(curve_points[i][0]), int(curve_points[i][1]))\n",
    "                pt2 = (int(curve_points[i+1][0]), int(curve_points[i+1][1]))\n",
    "                cv2.line(combined_mask, pt1, pt2, 255, 3)\n",
    "\n",
    "            validated_colors[color_name] = {\n",
    "                'original_data': color_data,\n",
    "                'validated_mask': combined_mask,\n",
    "                'valid_components': 1,\n",
    "                'rejected_components': 0,\n",
    "                'total_valid_area': len(curve_points),\n",
    "                'extracted_points': curve_points\n",
    "            }\n",
    "\n",
    "            extraction_results['successful'].append(color_name)\n",
    "            extraction_results['total_points'] += len(curve_points)\n",
    "\n",
    "            print(f\"\\tBLACK: {len(curve_points)} points extracted successfully\")\n",
    "\n",
    "        else:\n",
    "            extraction_results['failed'].append(color_name)\n",
    "            print(f\"\\tBLACK: No suitable curve found\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\tUSING SIMPLE DIRECT ALGORITHM...\")\n",
    "\n",
    "        curve_points = extract_simple_curve(\n",
    "            image_np,\n",
    "            axis_calibration['bounds'],\n",
    "            color_name,\n",
    "            color_data['range']\n",
    "        )\n",
    "\n",
    "        if curve_points is not None:\n",
    "            # Create visualization mask\n",
    "            combined_mask = np.zeros_like(color_data['mask'])\n",
    "\n",
    "            # Draw curve as lines and points\n",
    "            for i in range(len(curve_points)-1):\n",
    "                pt1 = (int(curve_points[i][0]), int(curve_points[i][1]))\n",
    "                pt2 = (int(curve_points[i+1][0]), int(curve_points[i+1][1]))\n",
    "                cv2.line(combined_mask, pt1, pt2, 255, 3)\n",
    "\n",
    "            for point in curve_points:\n",
    "                pt = (int(point[0]), int(point[1]))\n",
    "                cv2.circle(combined_mask, pt, 2, 255, -1)\n",
    "\n",
    "            validated_colors[color_name] = {\n",
    "                'original_data': color_data,\n",
    "                'validated_mask': combined_mask,\n",
    "                'valid_components': 1,\n",
    "                'rejected_components': 0,\n",
    "                'total_valid_area': len(curve_points),\n",
    "                'extracted_points': curve_points\n",
    "            }\n",
    "\n",
    "            extraction_results['successful'].append(color_name)\n",
    "            extraction_results['total_points'] += len(curve_points)\n",
    "\n",
    "            print(f\"\\t{color_name.upper()}: {len(curve_points)} points extracted successfully\")\n",
    "\n",
    "        else:\n",
    "            extraction_results['failed'].append(color_name)\n",
    "            print(f\"\\t{color_name.upper()}: No curve found\")\n",
    "\n",
    "# Prepare final data structure for subsequent cells\n",
    "extracted_curves = {}\n",
    "for color_name, data in validated_colors.items():\n",
    "    if 'extracted_points' in data:\n",
    "        extracted_curves[color_name] = {\n",
    "            'pixel_coordinates': data['extracted_points'],\n",
    "            'point_count': len(data['extracted_points']),\n",
    "            'scientific_coordinates': ([], []),\n",
    "            'confidence': data['original_data']['quality'],\n",
    "            'x_range': (np.min(data['extracted_points'][:, 0]), np.max(data['extracted_points'][:, 0])),\n",
    "            'y_range': (np.min(data['extracted_points'][:, 1]), np.max(data['extracted_points'][:, 1])),\n",
    "            'validation_data': data\n",
    "        }\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nUSER-CONTROLLED EXTRACTION COMPLETE!\")\n",
    "print(f\"\\tUser Request: '{extraction_instructions}'\" if extraction_instructions else \"ðŸ’¬ No specific user request\")\n",
    "print(f\"\\tExtraction Mode: {extraction_mode.upper()}\")\n",
    "print(f\"\\tColors Requested: {extraction_results['requested']}\")\n",
    "print(f\"\\tSuccessfully Extracted: {extraction_results['successful']}\")\n",
    "print(f\"\\tFailed to Extract: {extraction_results['failed']}\")\n",
    "print(f\"\\tTotal Data Points: {extraction_results['total_points']}\")\n",
    "print(f\"\\tCurves Ready: {len(extracted_curves)}\")\n",
    "\n",
    "if extraction_mode == \"selective\":\n",
    "    if len(extraction_results['successful']) == len(requested_colors):\n",
    "        print(f\"\\tPERFECT SUCCESS: Got exactly what you requested!\")\n",
    "    elif len(extraction_results['successful']) > 0:\n",
    "        print(f\"\\tPARTIAL SUCCESS: Got {len(extraction_results['successful'])}/{len(requested_colors)} requested colors\")\n",
    "    else:\n",
    "        print(f\"\\tFAILED: Could not extract any of the requested colors\")\n",
    "        print(f\"\\tSuggestions: Check color visibility, try different color names, or use 'auto' mode\")\n",
    "\n",
    "print(f\"\\nProceeding to visualization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lk1vkKobH4iU"
   },
   "outputs": [],
   "source": [
    "#CELL 9\n",
    "print(\"ANALYZING CURVE INTERSECTIONS AND OVERLAPS...\")\n",
    "\n",
    "def find_curve_intersections(curve1_coords, curve2_coords, tolerance=3):\n",
    "    \"\"\"Find intersection points between two curves\"\"\"\n",
    "    if len(curve1_coords) == 0 or len(curve2_coords) == 0:\n",
    "        return []\n",
    "\n",
    "    intersections = []\n",
    "\n",
    "    for i, point1 in enumerate(curve1_coords):\n",
    "        distances = np.linalg.norm(curve2_coords - point1, axis=1)\n",
    "        nearby_indices = np.where(distances <= tolerance)[0]\n",
    "\n",
    "        for j in nearby_indices:\n",
    "            point2 = curve2_coords[j]\n",
    "            intersection_point = (point1 + point2) / 2\n",
    "            intersections.append({\n",
    "                'position': intersection_point,\n",
    "                'curve1_index': i,\n",
    "                'curve2_index': j,\n",
    "                'distance': distances[j]\n",
    "            })\n",
    "\n",
    "    return intersections\n",
    "\n",
    "def analyze_pixel_color_at_intersection(image, intersection_point, color_ranges):\n",
    "    \"\"\"Analyze color dominance at intersection point\"\"\"\n",
    "    x, y = int(intersection_point[0]), int(intersection_point[1])\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    if 0 <= x < w and 0 <= y < h:\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        pixel_hsv = hsv_image[y, x]\n",
    "\n",
    "        color_distances = {}\n",
    "        for color_name, (lower, upper) in color_ranges.items():\n",
    "            center_hsv = [(lower[i] + upper[i]) / 2 for i in range(3)]\n",
    "            distance = np.linalg.norm(pixel_hsv - center_hsv)\n",
    "            color_distances[color_name] = distance\n",
    "\n",
    "        closest_color = min(color_distances, key=color_distances.get)\n",
    "        confidence = 1.0 / (1.0 + color_distances[closest_color] / 100)\n",
    "\n",
    "        return closest_color, confidence\n",
    "\n",
    "    return None, 0.0\n",
    "\n",
    "intersection_analysis = {}\n",
    "\n",
    "if len(extracted_curves) > 1:\n",
    "    print(\"\\nDetecting intersections between curves:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    curve_names = list(extracted_curves.keys())\n",
    "\n",
    "    for i in range(len(curve_names)):\n",
    "        for j in range(i + 1, len(curve_names)):\n",
    "            color1, color2 = curve_names[i], curve_names[j]\n",
    "\n",
    "            coords1 = extracted_curves[color1]['pixel_coordinates']\n",
    "            coords2 = extracted_curves[color2]['pixel_coordinates']\n",
    "\n",
    "            intersections = find_curve_intersections(coords1, coords2)\n",
    "\n",
    "            if intersections:\n",
    "                print(f\"{color1} â†” {color2}: {len(intersections)} intersections found\")\n",
    "\n",
    "                intersection_details = []\n",
    "                for intersection in intersections:\n",
    "                    dominant_color, confidence = analyze_pixel_color_at_intersection(\n",
    "                        image_np, intersection['position'],\n",
    "                        {color1: detected_colors[color1]['range'],\n",
    "                         color2: detected_colors[color2]['range']}\n",
    "                    )\n",
    "\n",
    "                    intersection_details.append({\n",
    "                        'position': intersection['position'],\n",
    "                        'dominant_color': dominant_color,\n",
    "                        'confidence': confidence,\n",
    "                        'distance': intersection['distance']\n",
    "                    })\n",
    "\n",
    "                intersection_analysis[f\"{color1}_{color2}\"] = {\n",
    "                    'intersections': intersection_details,\n",
    "                    'count': len(intersections),\n",
    "                    'quality': np.mean([detail['confidence'] for detail in intersection_details])\n",
    "                }\n",
    "\n",
    "                avg_confidence = np.mean([detail['confidence'] for detail in intersection_details])\n",
    "                print(f\"Average resolution confidence: {avg_confidence:.2f}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"{color1} â†” {color2}: No intersections detected\")\n",
    "\n",
    "    total_intersections = sum(data['count'] for data in intersection_analysis.values())\n",
    "    if total_intersections > 0:\n",
    "        avg_quality = np.mean([data['quality'] for data in intersection_analysis.values()])\n",
    "        print(f\"\\nIntersection Summary:\")\n",
    "        print(f\"Total intersections: {total_intersections}\")\n",
    "        print(f\"Average resolution quality: {avg_quality:.2f}\")\n",
    "\n",
    "        if avg_quality < 0.5:\n",
    "            print(\"Some intersections have low resolution confidence\")\n",
    "    else:\n",
    "        print(\"\\nNo curve intersections detected - clean extraction\")\n",
    "\n",
    "else:\n",
    "    print(\"Only one curve detected - no intersection analysis needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxUCgQ7FH-dC"
   },
   "outputs": [],
   "source": [
    "#CELL 10\n",
    "print(\"CURVE EXTRACTION QUALITY ASSESSMENT\")\n",
    "\n",
    "def calculate_overall_quality_score(curve_data):\n",
    "    point_count = curve_data['point_count']\n",
    "    density_score = min(point_count / 200, 1.0)\n",
    "    overall_quality = density_score\n",
    "    return overall_quality, {'density_score': density_score}\n",
    "\n",
    "quality_assessment = {}\n",
    "overall_success_metrics = {'high_quality': 0, 'medium_quality': 0, 'low_quality': 0}\n",
    "\n",
    "print(\"\\nIndividual Curve Quality Analysis:\")\n",
    "\n",
    "for color_name, curve_data in extracted_curves.items():\n",
    "    overall_quality, quality_details = calculate_overall_quality_score(curve_data)\n",
    "\n",
    "    if overall_quality >= 0.75:\n",
    "        quality_level = \"HIGH\"\n",
    "        overall_success_metrics['high_quality'] += 1\n",
    "    elif overall_quality >= 0.5:\n",
    "        quality_level = \"MEDIUM\"\n",
    "        overall_success_metrics['medium_quality'] += 1\n",
    "    else:\n",
    "        quality_level = \"LOW\"\n",
    "        overall_success_metrics['low_quality'] += 1\n",
    "\n",
    "    quality_assessment[color_name] = {\n",
    "        'overall_quality': overall_quality,\n",
    "        'quality_level': quality_level\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{color_name.upper()} CURVE - {quality_level} QUALITY\")\n",
    "    print(f\"Overall Score: {overall_quality:.2f}\")\n",
    "    print(f\"Points Extracted: {curve_data['point_count']}\")\n",
    "\n",
    "print(f\"\\nOVERALL EXTRACTION SUMMARY\")\n",
    "print(f\"High quality extractions: {overall_success_metrics['high_quality']}\")\n",
    "print(f\"Medium quality extractions: {overall_success_metrics['medium_quality']}\")\n",
    "print(f\"Low quality extractions: {overall_success_metrics['low_quality']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJ9MFXEpAFKG"
   },
   "outputs": [],
   "source": [
    "#CELL 11\n",
    "print(\"VISUAL VALIDATION - CONFIRM EXTRACTION QUALITY\")\n",
    "\n",
    "excel_export_approved = False\n",
    "print(\"Export approval status RESET - you must click a button below to proceed\")\n",
    "\n",
    "def create_curve_overlay_visualization(original_image, extracted_curves):\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    ax1.imshow(original_image)\n",
    "    ax1.set_title('Original Image with Extracted Curves', fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    colors = ['red', 'blue', 'green', 'gold', 'teal', 'purple', 'orange', 'brown', 'gray', 'cyan', 'magenta', 'darkblue', 'darkgreen']\n",
    "\n",
    "    for i, (color_name, curve_data) in enumerate(extracted_curves.items()):\n",
    "        coords = curve_data['pixel_coordinates']\n",
    "        if len(coords) > 0:\n",
    "            plot_color = colors[i % len(colors)]\n",
    "\n",
    "            if len(coords) > 200:\n",
    "                step = max(1, len(coords) // 200)\n",
    "                display_coords = coords[::step]\n",
    "            else:\n",
    "                display_coords = coords\n",
    "\n",
    "            ax1.plot(display_coords[:, 0], display_coords[:, 1],\n",
    "                    color=plot_color, linewidth=2, alpha=0.8,\n",
    "                    label=f'{color_name} ({len(coords)} pts)')\n",
    "\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    return fig\n",
    "\n",
    "print(\"\\nCreating comprehensive visualization...\")\n",
    "if 'extracted_curves' in globals() and extracted_curves:\n",
    "    visualization_figure = create_curve_overlay_visualization(image_np, extracted_curves)\n",
    "    plt.show(visualization_figure)\n",
    "\n",
    "    print(f\"\\nVALIDATION SUMMARY:\")\n",
    "    print(f\"Curves analyzed: {len(extracted_curves)}\")\n",
    "    for color_name, curve_data in extracted_curves.items():\n",
    "        print(f\"  {color_name}: {curve_data['point_count']} points extracted\")\n",
    "\n",
    "    print(\"DATA EXPORT OPTION\")\n",
    "    print(f\"Available curves for export: {list(extracted_curves.keys())}\")\n",
    "    print(f\"Total data points ready: {sum(len(curve['pixel_coordinates']) for curve in extracted_curves.values())}\")\n",
    "\n",
    "    print(\"\\nEXCEL EXPORT DECISION:\")\n",
    "    print(\"Click the button below to approve Excel export:\")\n",
    "\n",
    "    export_button = widgets.Button(\n",
    "        description='APPROVE EXCEL EXPORT',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(width='300px', height='50px')\n",
    "    )\n",
    "\n",
    "    decline_button = widgets.Button(\n",
    "        description='DECLINE EXCEL EXPORT',\n",
    "        button_style='danger',\n",
    "        layout=widgets.Layout(width='300px', height='50px')\n",
    "    )\n",
    "\n",
    "    output = widgets.Output()\n",
    "\n",
    "    def on_approve_clicked(b):\n",
    "        import __main__\n",
    "        __main__.excel_export_approved = True\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Excel export APPROVED!\")\n",
    "            print(\"Creating Excel file...\")\n",
    "\n",
    "            try:\n",
    "                if 'extracted_curves' not in globals() or not extracted_curves:\n",
    "                    print(\"ERROR: No extracted curves found!\")\n",
    "                    return\n",
    "\n",
    "                print(f\"Found {len(extracted_curves)} curves for export\")\n",
    "\n",
    "                def convert_pixel_to_scientific(pixel_coords, axis_calibration):\n",
    "                    x_pixel = axis_calibration['x_pixel']\n",
    "                    y_pixel = axis_calibration['y_pixel']\n",
    "                    x_real = axis_calibration['x_real']\n",
    "                    y_real = axis_calibration['y_real']\n",
    "                    x_scale = axis_calibration.get('x_scale', 'linear')\n",
    "                    y_scale = axis_calibration.get('y_scale', 'linear')\n",
    "\n",
    "                    scientific_x = []\n",
    "                    scientific_y = []\n",
    "\n",
    "                    for px, py in pixel_coords:\n",
    "                        if x_scale == 'linear':\n",
    "                            x_scientific = x_real[0] + (px - x_pixel[0]) * (x_real[1] - x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "                        elif x_scale == 'log10':\n",
    "                            log_x_real = [np.log10(max(x_real[0], 1e-10)), np.log10(max(x_real[1], 1e-10))]\n",
    "                            log_x_interp = log_x_real[0] + (px - x_pixel[0]) * (log_x_real[1] - log_x_real[0]) / (x_pixel[1] - x_pixel[0])\n",
    "                            x_scientific = 10 ** log_x_interp\n",
    "                        else:\n",
    "                            x_scientific = px\n",
    "\n",
    "                        if y_scale == 'linear':\n",
    "                            y_scientific = y_real[0] + (py - y_pixel[0]) * (y_real[1] - y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "                        elif y_scale == 'log10':\n",
    "                            log_y_real = [np.log10(max(y_real[0], 1e-10)), np.log10(max(y_real[1], 1e-10))]\n",
    "                            log_y_interp = log_y_real[0] + (py - y_pixel[0]) * (log_y_real[1] - log_y_real[0]) / (y_pixel[1] - y_pixel[0])\n",
    "                            y_scientific = 10 ** log_y_interp\n",
    "                        else:\n",
    "                            y_scientific = py\n",
    "\n",
    "                        scientific_x.append(x_scientific)\n",
    "                        scientific_y.append(y_scientific)\n",
    "\n",
    "                    return np.array(scientific_x), np.array(scientific_y)\n",
    "\n",
    "                def create_excel_export():\n",
    "\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    filename = f\"curve_data_{timestamp}.xlsx\"\n",
    "\n",
    "                    print(f\"Creating Excel file: {filename}\")\n",
    "\n",
    "                    if 'axis_calibration' in globals():\n",
    "                        axis_cal = axis_calibration\n",
    "                        print(\"Using axis calibration from pipeline\")\n",
    "                    else:\n",
    "                        h, w = image_np.shape[:2]\n",
    "                        axis_cal = {\n",
    "                            'x_pixel': [int(w * 0.15), int(w * 0.90)],\n",
    "                            'y_pixel': [int(h * 0.85), int(h * 0.10)],\n",
    "                            'x_real': [0, 1000],\n",
    "                            'y_real': [0.001, 10],\n",
    "                            'x_scale': 'linear',\n",
    "                            'y_scale': 'log10'\n",
    "                        }\n",
    "                        print(\"Using fallback axis calibration\")\n",
    "\n",
    "                    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "                        for color_name, curve_data in extracted_curves.items():\n",
    "                            print(f\"Processing {color_name} curve...\")\n",
    "\n",
    "                            pixel_coords = curve_data['pixel_coordinates']\n",
    "\n",
    "                            x_scientific, y_scientific = convert_pixel_to_scientific(pixel_coords, axis_cal)\n",
    "\n",
    "                            print(f\"      X range: {np.min(x_scientific):.3f} to {np.max(x_scientific):.3f}\")\n",
    "                            print(f\"      Y range: {np.min(y_scientific):.6f} to {np.max(y_scientific):.6f}\")\n",
    "\n",
    "                            simple_data = pd.DataFrame({\n",
    "                                'X': x_scientific,\n",
    "                                'Y': y_scientific\n",
    "                            })\n",
    "\n",
    "                            sheet_name = color_name[:31]\n",
    "                            simple_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "                            print(f\"{color_name}: {len(x_scientific)} data points exported\")\n",
    "\n",
    "                    print(f\"Excel file created successfully: {filename}\")\n",
    "\n",
    "                    import os\n",
    "                    if os.path.exists(filename):\n",
    "                        file_size = os.path.getsize(filename)\n",
    "                        print(f\"File confirmed: {file_size} bytes\")\n",
    "                    else:\n",
    "                        print(f\"ERROR: File was not created!\")\n",
    "                        return False\n",
    "\n",
    "                    try:\n",
    "                        files.download(filename)\n",
    "                        print(f\"File download initiated!\")\n",
    "                        return True\n",
    "                    except Exception as download_error:\n",
    "                        print(f\"Auto-download failed: {str(download_error)}\")\n",
    "                        print(f\"File saved as: {filename}\")\n",
    "                        return True\n",
    "\n",
    "                export_success = create_excel_export()\n",
    "\n",
    "                if export_success:\n",
    "                    print(f\"\\nEXCEL EXPORT COMPLETE!\")\n",
    "\n",
    "                    total_points = sum(curve['point_count'] for curve in extracted_curves.values())\n",
    "                    print(f\"\\nEXPORT SUMMARY:\")\n",
    "                    print(f\"Curves exported: {', '.join(extracted_curves.keys())}\")\n",
    "                    print(f\"Total data points: {total_points}\")\n",
    "                else:\n",
    "                    print(f\"\\nEXCEL EXPORT FAILED!\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Excel export failed with error: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "\n",
    "    def on_decline_clicked(b):\n",
    "        import __main__\n",
    "        __main__.excel_export_approved = False\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Excel export DECLINED.\")\n",
    "            print(\"You can click APPROVE above if you change your mind.\")\n",
    "\n",
    "    export_button.on_click(on_approve_clicked)\n",
    "    decline_button.on_click(on_decline_clicked)\n",
    "\n",
    "    button_box = widgets.HBox([export_button, decline_button])\n",
    "    display(button_box)\n",
    "    display(output)\n",
    "\n",
    "    print(f\"\\nVISUALIZATION COMPLETE!\")\n",
    "    print(f\"Use the buttons above to approve/decline Excel export\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo curves found for visualization!\")\n",
    "    print(\"Please run the extraction pipeline first:\")\n",
    "    print(\"Go to Cell 5\")\n",
    "    print(\"Ask: 'extract the black line' (or your desired color)\")\n",
    "    print(\"Wait for pipeline to complete\")\n",
    "    print(\"Then run this Cell 11 again\")\n",
    "\n",
    "print(f\"\\nLine Extraction Process Complete!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
